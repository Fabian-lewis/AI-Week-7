{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN40DQ6X5YNiehIDxcchot6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fabian-lewis/AI-Week-7/blob/main/TheoreticalUnderstanding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Short Answer Questions\n",
        "###Q1: Define algorithmic bias and provide two examples of how it manifests in AI systems.\n",
        "Agorithimic bias refers to systematic and repeatable errors in AI systems that result in unfair outcomes, often disadvantaging certain groups.\n",
        "Its main cause s ussually biased data, flawed assumptions or inappropriate model design.\n",
        "\n",
        "Examples:\n",
        "\n",
        "  1. Hiring Algorithms\n",
        "  \n",
        "  A recruitment AI trained on historical hiring data may favor male candidates if past company practices were biased, leading to gender discrimination.\n",
        "\n",
        "  2. Credit Scoring Models\n",
        "\n",
        "  An AI model might unfairly deny loans to applicants from certain ethnic groups if trained on biased financial data reflecting historical discrimination.\n",
        "\n",
        "###Q2: Explain the difference between transparency and explainability in AI. Why are both important?\n",
        "Transparency refers to how open and clear the AI system's design, data sources, and decision making-processes are to stakeholders. Explainability on the other hand, focuses on the ability to make AI decision understandable to humans - explaining why and how a model arrived at a specific outcome.\n",
        "\n",
        "Why are they important:\n",
        "\n",
        "  - Transparency fosters trust and accountabiity in AI systems\n",
        "  - Explainability enables users, regulators, and developers to interpret decisions, identify errors, and ensure fairness.\n",
        "\n",
        "\n",
        "###Q3: How does GDPR (General Data Protection Regulation) impact AI development in the EU?\n",
        "GDPR directly affects AI by enforcing strict rules on data privacy, consent and individual rights within the EU\n",
        "\n",
        "Key Impacts:\n",
        "\n",
        "1. Data Minimization\n",
        "\n",
        "AI developers must limit data collection to whatever is necessary for the specific purpose.\n",
        "\n",
        "2. Right to Explantion\n",
        "\n",
        "Individuals have the right to receive meaningfil explanations of automated decisions(Article 22), pushing AI towards greater explainabiity\n",
        "\n",
        "\n",
        "3. Accountability\n",
        "\n",
        "Developers must ensure compliance with GDPR principles rewuiring transparent data processing and safeguards against misuse. This has led to a shift towards privacy-preserving AI methods like federated learning and anonymization techniques.\n",
        "\n",
        "\n",
        "##Ethical Principles Matching\n",
        "\n",
        "Match the following principles to their definitions:\n",
        "\n",
        "| Principle          | Definition                                                   |\n",
        "| ------------------ | ------------------------------------------------------------ |\n",
        "| B) Non-maleficence | Ensuring AI does not harm individuals or society.            |\n",
        "| C) Autonomy        | Respecting users’ right to control their data and decisions. |\n",
        "| D) Sustainability  | Designing AI to be environmentally friendly.                 |\n",
        "| A) Justice         | Fair distribution of AI benefits and risks.                  |\n",
        "\n",
        "\n",
        "\n",
        "##Part 2: Case Study Analysis\n",
        "###Case 1: Biased Hiring Tool - Amazon’s AI recruiting tool penalized female candidates.\n",
        "\n",
        "Source of Bias:\n",
        "\n",
        "1. Training Data Bias\n",
        "\n",
        "The tool learned from historical resumes, which reflected past hiring biases favoring male candidates in tech roles.\n",
        "\n",
        "2. Model Design Bias\n",
        "\n",
        "The algorithm may have been optimized on biased performance metrics, reinforcing existing discrimination patterns.\n",
        "\n",
        "Three Fixes to Make the Tool Fairer:\n",
        "\n",
        "  1. Audit and Clean Training Data\n",
        "  \n",
        "  Remove gender-related features and historical biases from the dataset.\n",
        "\n",
        "  2. Implement Fairness-Aware Algorithms\n",
        "  \n",
        "  Use algorithms designed to detect and correct for bias (e.g., adversarial debiasing).\n",
        "\n",
        "  3. Human Oversight and Regular Audits\n",
        "  \n",
        "  Introduce continuous human review of AI decisions and regular fairness audits.\n",
        "\n",
        "Fairness Metrics to Use:\n",
        "\n",
        "  1. Demographic Parity\n",
        "  \n",
        "  Ensure equal selection rates across genders.\n",
        "\n",
        "  2. Equal Opportunity\n",
        "  \n",
        "  Verify that qualified candidates of all genders have equal chances of selection.\n",
        "\n",
        "  3. Disparate Impact Ratio\n",
        "  \n",
        "  Monitor adverse impact across different demographic groups.\n",
        "\n",
        "###Case 2: Facial Recognition in Policing - A facial recognition system misidentifies minorities at higher rates.\n",
        "\n",
        "Ethical Risks:\n",
        "\n",
        "1. Wrongful Arrests\n",
        "\n",
        "False positives can lead to detaining innocent people, especially minorities.\n",
        "\n",
        "2. Privacy Violations\n",
        "\n",
        "Continuous surveillance infringes on individuals’ rights to privacy.\n",
        "\n",
        "3. Discrimination & Bias Reinforcement\n",
        "\n",
        "Targeted over-policing of certain communities based on flawed AI outputs.\n",
        "\n",
        "Recommended Policies for Responsible Deployment:\n",
        "\n",
        "1. Strict Use Guidelines\n",
        "\n",
        "Restrict usage to well-defined, high-necessity scenarios (e.g., confirmed threats).\n",
        "\n",
        "2. Mandatory Bias Testing\n",
        "\n",
        "Require pre-deployment audits for accuracy across demographics.\n",
        "\n",
        "3. Transparency & Accountability\n",
        "\n",
        "Publicly disclose system usage and error rates; establish oversight bodies.\n",
        "\n",
        "4. Consent & Legal Safeguards\n",
        "\n",
        "Ensure deployments comply with privacy laws and receive public consent where applicable.\n"
      ],
      "metadata": {
        "id": "vwraqANS2rqK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Beb3VyiB2nIm"
      },
      "outputs": [],
      "source": []
    }
  ]
}